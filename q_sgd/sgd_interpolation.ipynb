{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yT-0ntjx4BPI"
   },
   "source": [
    "# Watching SGD in action with constant step sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_avg(X, y, w):\n",
    "    return (1/X.shape[0])*LA.norm(X@w - y, ord=2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_update(X, y, w, eta):\n",
    "    return w - (2.0 * eta/X.shape[0])*(X.transpose()@(X@w - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (1). Under-parameterized ($n > d$) Noiseless ($\\sigma=0$) Regime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZXfKbwY4BPJ"
   },
   "outputs": [],
   "source": [
    "# Generate data\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set number of samples\n",
    "N = 2000\n",
    "# Set the dimension\n",
    "d = 200\n",
    "\n",
    "# Generate data matrix X_train\n",
    "X_train = np.random.randn(N, d)\n",
    "# Generate ground truth w_star\n",
    "w_star = np.random.randn(d, 1)\n",
    "\n",
    "# Generate outputs y_train\n",
    "y_train = X_train @ w_star\n",
    "# Set mini batch size\n",
    "batch_size = 64\n",
    "# Set step size\n",
    "eta = 0.01\n",
    "# Set number of iterations\n",
    "N_iteration = 10000\n",
    "\n",
    "# Evaluate the largest and smallest eigenvalue\n",
    "_, s, _ = np.linalg.svd(X_train/np.sqrt(N))\n",
    "print('largest eigenvalue: ', s[0]**2)\n",
    "print('smallest eigenvalue: ', s[-1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BatchSizeList = [1, 64, 128]\n",
    "EtaList = [0.005, 0.002, 0.001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study the effect of step size $\\eta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_init = (np.random.randn(d, 1)) * 0.0\n",
    "\n",
    "Losses = []\n",
    "batch_size = 64\n",
    "for eta in EtaList:\n",
    "    loss = []\n",
    "    w = w_init.copy()\n",
    "    for i in range(N_iteration):\n",
    "        random_index = np.random.choice(N, batch_size)\n",
    "        X_i = X_train[random_index, :]\n",
    "        y_i = y_train[random_index]\n",
    "        w = SGD_update(X_i, y_i, w, eta)\n",
    "        loss.append(compute_loss_avg(X_train, y_train, w))\n",
    "    Losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "idx = 0\n",
    "for eta in EtaList:\n",
    "    plt.semilogy(range(N_iteration), Losses[idx], label = 'step size = {}'.format(eta))\n",
    "    idx += 1\n",
    "plt.axis('tight')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study the effect of mini batch size $|\\mathcal{S}_{t}|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_init = (np.random.randn(d, 1)) * 0.0\n",
    "Losses = []\n",
    "eta = 0.001\n",
    "for batch_size in BatchSizeList:\n",
    "    loss = []\n",
    "    w = w_init.copy()\n",
    "    for i in range(N_iteration):\n",
    "        random_index = np.random.choice(N, batch_size)\n",
    "        X_i = X_train[random_index, :]\n",
    "        y_i = y_train[random_index]\n",
    "        w = SGD_update(X_i, y_i, w, eta)\n",
    "        loss.append(compute_loss_avg(X_train, y_train, w))\n",
    "    Losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "idx = 0\n",
    "for batch_size in BatchSizeList:\n",
    "    plt.semilogy(range(N_iteration), Losses[idx], label = 'mini batch size = {}'.format(batch_size))\n",
    "    idx += 1\n",
    "plt.axis('tight')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (2). Over-parameterized ($n < d$) Noiseless ($\\sigma=0$) Regime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PV4CQY187_13"
   },
   "outputs": [],
   "source": [
    "# Generate data\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set number of samples\n",
    "N = 500\n",
    "# Set the dimension\n",
    "d = 1000\n",
    "\n",
    "# Generate data matrix X_train\n",
    "X_train = np.random.randn(N, d)\n",
    "# Generate ground truth w_star\n",
    "w_star = np.random.randn(d, 1)\n",
    "\n",
    "# Generate outputs y_train\n",
    "y_train = X_train @ w_star\n",
    "# Set mini batch size\n",
    "batch_size = 64\n",
    "# Set step size\n",
    "eta = 0.001\n",
    "# Set number of iterations\n",
    "N_iteration = 50000\n",
    "\n",
    "\n",
    "# Evaluate the largest and smallest eigenvalue\n",
    "_, s, _ = np.linalg.svd(X_train/np.sqrt(N))\n",
    "print('largest eigenvalue: ', s[0]**2)\n",
    "print('smallest singular value (square): ', s[-1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BatchSizeList = [1, 64, 128]\n",
    "EtaList = [0.002, 0.001, 0.0005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study the effect of step size $\\eta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_init = (np.random.randn(d, 1)) * 0.0\n",
    "\n",
    "Losses = []\n",
    "batch_size = 64\n",
    "for eta in EtaList:\n",
    "    loss = []\n",
    "    w = w_init.copy()\n",
    "    for i in range(N_iteration):\n",
    "        random_index = np.random.choice(N, batch_size)\n",
    "        X_i = X_train[random_index, :]\n",
    "        y_i = y_train[random_index]\n",
    "        w = SGD_update(X_i, y_i, w, eta)\n",
    "        loss.append(compute_loss_avg(X_train, y_train, w))\n",
    "    Losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "idx = 0\n",
    "for eta in EtaList:\n",
    "    plt.semilogy(range(N_iteration), Losses[idx], label = 'step size = {}'.format(eta))\n",
    "    idx += 1\n",
    "plt.axis('tight')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study the effect of mini batch size $|\\mathcal{S}_{t}|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_init = (np.random.randn(d, 1)) * 0.0\n",
    "Losses = []\n",
    "eta = 0.0005\n",
    "for batch_size in BatchSizeList:\n",
    "    loss = []\n",
    "    w = w_init.copy()\n",
    "    for i in range(N_iteration):\n",
    "        random_index = np.random.choice(N, batch_size)\n",
    "        X_i = X_train[random_index, :]\n",
    "        y_i = y_train[random_index]\n",
    "        w = SGD_update(X_i, y_i, w, eta)\n",
    "        loss.append(compute_loss_avg(X_train, y_train, w))\n",
    "    Losses.append(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "idx = 0\n",
    "for batch_size in BatchSizeList:\n",
    "    plt.semilogy(range(N_iteration), Losses[idx], label = 'mini batch size = {}'.format(batch_size))\n",
    "    idx += 1\n",
    "plt.axis('tight')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (3). Over-parameterized ($n < d$) Noise ($\\sigma>0$) Regime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set number of samples\n",
    "N = 500\n",
    "# Set the dimension\n",
    "d = 1000\n",
    "\n",
    "# Generate data matrix X_train\n",
    "X_train = np.random.randn(N, d)\n",
    "# Generate ground truth w_star\n",
    "w_star = np.random.randn(d, 1)\n",
    "\n",
    "# Generate outputs y_train\n",
    "y_train = X_train @ w_star + 0.1 * np.random.randn(N, 1)\n",
    "# Set mini batch size\n",
    "batch_size = 64\n",
    "# Set step size\n",
    "eta = 0.001\n",
    "# Set number of iterations\n",
    "N_iteration = 50000\n",
    "\n",
    "\n",
    "# Evaluate the largest and smallest eigenvalue\n",
    "X_train = np.concatenate((X_train, 0.1 * np.eye(N)), axis=1)\n",
    "_, s, _ = np.linalg.svd(X_train/np.sqrt(N))\n",
    "print('largest eigenvalue: ', s[0]**2)\n",
    "print('smallest singular value (square): ', s[-1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Study the effect of step size $\\eta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_init = (np.random.randn(d + N, 1)) * 0.0\n",
    "\n",
    "Losses = []\n",
    "batch_size = 64\n",
    "for eta in EtaList:\n",
    "    loss = []\n",
    "    w = w_init.copy()\n",
    "    for i in range(N_iteration):\n",
    "        random_index = np.random.choice(N, batch_size)\n",
    "        X_i = X_train[random_index, :]\n",
    "        y_i = y_train[random_index]\n",
    "        w = SGD_update(X_i, y_i, w, eta)\n",
    "        loss.append(compute_loss_avg(X_train, y_train, w))\n",
    "    Losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "idx = 0\n",
    "for eta in EtaList:\n",
    "    plt.semilogy(range(N_iteration), Losses[idx], label = 'step size = {}'.format(eta))\n",
    "    idx += 1\n",
    "plt.axis('tight')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Study the effect of mini batch size $|\\mathcal{S}_{t}|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_init = (np.random.randn(d + N, 1)) * 0.0\n",
    "Losses = []\n",
    "eta = 0.0005\n",
    "for batch_size in BatchSizeList:\n",
    "    loss = []\n",
    "    w = w_init.copy()\n",
    "    for i in range(N_iteration):\n",
    "        random_index = np.random.choice(N, batch_size)\n",
    "        X_i = X_train[random_index, :]\n",
    "        y_i = y_train[random_index]\n",
    "        w = SGD_update(X_i, y_i, w, eta)\n",
    "        loss.append(compute_loss_avg(X_train, y_train, w))\n",
    "    Losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "idx = 0\n",
    "for batch_size in BatchSizeList:\n",
    "    plt.semilogy(range(N_iteration), Losses[idx], label = 'mini batch size = {}'.format(batch_size))\n",
    "    idx += 1\n",
    "plt.axis('tight')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (4). Under-parameterized ($n > d$) Noise ($\\sigma>0$) Regime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare SGD on original ridge regression and feature-augmented regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set number of samples\n",
    "N = 500\n",
    "# Set the dimension\n",
    "d = 50\n",
    "\n",
    "# Generate data matrix X_train\n",
    "X_train = np.random.randn(N, d)\n",
    "# Generate ground truth w_star\n",
    "w_star = np.random.randn(d, 1)\n",
    "\n",
    "# Generate outputs y_train\n",
    "y_train = X_train @ w_star + 0.1 * np.random.randn(N, 1)\n",
    "y_train_clean = X_train @ w_star\n",
    "# Set mini batch size\n",
    "batch_size = 64\n",
    "# Set step size\n",
    "eta = 0.001\n",
    "# Set number of iterations\n",
    "N_iteration = 500000\n",
    "\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "w_star = np.linalg.inv(X_train.transpose()@X_train + N * alpha * np.eye(d))@X_train.transpose()@y_train\n",
    "w_star_clean = np.linalg.inv(X_train.transpose()@X_train)@X_train.transpose()@y_train_clean\n",
    "\n",
    "\n",
    "# Evaluate the largest and smallest eigenvalue\n",
    "X_train_aug = np.concatenate((X_train, np.sqrt(N * alpha) * np.eye(N)), axis=1)\n",
    "_, s, _ = np.linalg.svd(X_train_aug/np.sqrt(N))\n",
    "print('largest eigenvalue: ', s[0]**2)\n",
    "print('smallest singular value (square): ', s[-1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_diff_norm(w, w_star):\n",
    "    return LA.norm(w - w_star, ord=2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_update_ridge(X, y, w, eta, alpha = 0.01):\n",
    "    return w - (2.0 * eta/X.shape[0])*(X.transpose()@(X@w - y)) - 2.0 * eta * alpha * w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run SGD on original ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_init = (np.random.randn(d, 1)) * 0.0\n",
    "loss_ridge = []\n",
    "w = w_init.copy()\n",
    "for i in range(N_iteration):\n",
    "    random_index = np.random.choice(N, batch_size)\n",
    "    X_i = X_train[random_index, :]\n",
    "    y_i = y_train[random_index]\n",
    "    w = SGD_update_ridge(X_i, y_i, w, eta, alpha)\n",
    "    loss_ridge.append(compute_diff_norm(w, w_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(range(N_iteration), loss_ridge, label = 'Original Ridge')\n",
    "plt.axis('tight')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"||w-w*||^2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run SGD on original regression (but with no noise in $y$, i.e., $\\sigma=0.0$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_init = (np.random.randn(d, 1)) * 0.0\n",
    "loss_ridge_clean = []\n",
    "w = w_init.copy()\n",
    "for i in range(N_iteration):\n",
    "    random_index = np.random.choice(N, batch_size)\n",
    "    X_i = X_train[random_index, :]\n",
    "    y_i = y_train_clean[random_index]\n",
    "    w = SGD_update(X_i, y_i, w, eta)\n",
    "    loss_ridge_clean.append(compute_diff_norm(w, w_star_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(range(N_iteration), loss_ridge_clean, label = 'Original (no noise, without regularization)')\n",
    "plt.axis('tight')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"||w-w*||^2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run SGD on augmented regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_aug_init = (np.random.randn(d + N, 1)) * 0.0\n",
    "\n",
    "loss_aug = []\n",
    "w_aug = w_aug_init.copy()\n",
    "for i in range(N_iteration):\n",
    "    random_index = np.random.choice(N, batch_size)\n",
    "    X_i = X_train_aug[random_index, :]\n",
    "    y_i = y_train[random_index]\n",
    "    w_aug = SGD_update(X_i, y_i, w_aug, eta)\n",
    "    loss_aug.append(compute_diff_norm(w_aug[:d], w_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(range(N_iteration), loss_aug, label = 'Feature Augmented')\n",
    "plt.axis('tight')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"||w-w*||^2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the above three figures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(range(N_iteration), loss_aug, label = 'Feature Augmented')\n",
    "plt.semilogy(range(N_iteration), loss_ridge, label = 'Original Ridge')\n",
    "plt.semilogy(range(N_iteration), loss_ridge_clean, label = 'Original (no noise, without regularization)')\n",
    "plt.axis('tight')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"||w-w*||^2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zoom in Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(range(N_iteration)[:10000], loss_aug[:10000], label = 'Feature Augmented')\n",
    "plt.semilogy(range(N_iteration)[:10000], loss_ridge[:10000], label = 'Original Ridge')\n",
    "plt.semilogy(range(N_iteration)[:10000], loss_ridge_clean[:10000], label = 'Original (no noise, without regularization)')\n",
    "plt.axis('tight')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"||w-w*||^2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stochastic Gradient Descent with Constant Step Size.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
