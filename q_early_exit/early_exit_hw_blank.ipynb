{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting Example Difficulty in Practice with Early Exit\n",
    "\n",
    "In the last notebook we explored the concept of example difficulty and prediction depth. How can we use this knowledge to our advantage? What kind of benefits can we see by leveraging our understanding of example difficulty. \n",
    "\n",
    "In many growing domains of machine learning, we often will have systems constraints like inference latency, energy usage, etc. \n",
    "\n",
    "As we noticed in the last homework, some examples actually don't need to be passed through the entire network. This concept was formalized as prediction depth.\n",
    "\n",
    "So why do we need to pass the inputs through the entire network if they can be predicted correctly by an earlier layer?\n",
    "\n",
    "Are there tradeoffs associated with not going through the entire network? \n",
    "\n",
    "Much of this homework was inspired by the following paper:\n",
    "\n",
    "https://arxiv.org/abs/1709.01686\n",
    "\n",
    "## Connecting to Example Difficulty\n",
    "\n",
    "In the last homework, we used KNN classifiers to determine prediction depth and visualize patterns that related image size and shape to the prediction difficulty. However, we don't actually need these KNN classifiers. What if we just replaced the KNN classifers with output heads and sent gradients through? This is the main idea behind BranchyNet.\n",
    "\n",
    "We seek to improve inference speed by simply exiting the network when a prediction is made with reasonably high confidence.\n",
    "\n",
    "## Concepts of BranchyNet\n",
    "\n",
    "We will now have N exits, as we did with the KNN classifiers. However, now each exit will contribute to the loss in the following manner\n",
    "\n",
    "$L_{\\text{early exit}}(\\hat{y}, y; \\theta) = \\sum_{i=1}^N w_i L(\\hat{y_{\\text{exit}}}, y; \\theta)$\n",
    "\n",
    "We will set the total loss of the network be a weighted sum of the standard cross entropy losses at each exit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline ResNet-18\n",
    "\n",
    "To properly see the effects of Early Exit, let's set up a resnet without early exit as a baseline for computation and inference speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "import torchprofile\n",
    "from tqdm import tqdm\n",
    "from architectures import EarlyExitResNet18\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MACS\n",
    "\n",
    "MACS stands for multiply and accumulate - In the hardware, this corresponds to multiplying, then adding a number to an accumulator. We use MACS as a measurement of the amount of computation used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_macs(model, inputs) -> int:\n",
    "    return torchprofile.profile_macs(model, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up our dataloader in the standard fashion. Similar to last homework, please download the data and put it in the same folder as this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data.npy', allow_pickle=True).item()\n",
    "x_tensor = torch.FloatTensor(data['x'])\n",
    "y_tensor = torch.LongTensor(data['y'])\n",
    "dataset = torch.utils.data.TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "test_data = np.load('test_data.npy', allow_pickle=True).item()\n",
    "x_tensor = torch.FloatTensor(test_data['x'])\n",
    "y_tensor = torch.LongTensor(test_data['y'])\n",
    "test_dataset = torch.utils.data.TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                       # Convert arrays to PIL images\n",
    "    transforms.Grayscale(num_output_channels=3),   # Convert grayscale to RGB\n",
    "    transforms.Resize((224, 224)),                 # Resize all images to 224x224\n",
    "    transforms.ToTensor(),                      # Convert the images to PyTorch tensors\n",
    "])\n",
    "\n",
    "\n",
    "resnet_dataset = deepcopy(dataset)\n",
    "resnet_test_dataset = deepcopy(test_dataset)\n",
    "\n",
    "resnet_dataset.transform = transform\n",
    "resnet_trainloader = torch.utils.data.DataLoader(resnet_dataset, batch_size=batch_size, num_workers=2, shuffle=True)\n",
    "\n",
    "resnet_test_dataset.transform = transform\n",
    "resnet_testloader = torch.utils.data.DataLoader(resnet_test_dataset, batch_size=128, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = EarlyExitResNet18()\n",
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "resnet_optimizer = optim.Adam(resnet.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Let's train a standard ResNet. Don't forget to pass in an entropy tolerance and set early_exit to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 50] loss: 1.128\n",
      "[1, 100] loss: 0.377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:08<01:15,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 50] loss: 0.153\n",
      "[2, 100] loss: 0.126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:16<01:08,  8.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 50] loss: 0.071\n",
      "[3, 100] loss: 0.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:25<00:59,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 50] loss: 0.036\n",
      "[4, 100] loss: 0.032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:34<00:51,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 50] loss: 0.023\n",
      "[5, 100] loss: 0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:42<00:42,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 50] loss: 0.014\n",
      "[6, 100] loss: 0.014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:51<00:34,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 50] loss: 0.022\n",
      "[7, 100] loss: 0.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:59<00:25,  8.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 50] loss: 0.007\n",
      "[8, 100] loss: 0.009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:08<00:16,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 50] loss: 0.009\n",
      "[9, 100] loss: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:16<00:08,  8.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 50] loss: 0.007\n",
      "[10, 100] loss: 0.011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:24<00:00,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "resnet_losses = []\n",
    "for epoch in tqdm(range(10)):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(resnet_trainloader, 0):\n",
    "        step += 1\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        inputs = inputs.repeat(1, 3, 1, 1)\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        resnet_optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "        # forward + backward + optimize\n",
    "        # TODO\n",
    "        outputs = ... \n",
    "        loss = ...\n",
    "        loss.backward()\n",
    "        resnet_optimizer.step()\n",
    "        resnet_losses.append(loss.item())\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 50:.3f}')\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in the code below to evaluate the ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [00:02, 19.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9078333377838135 %\n",
      "Total MACS:  3336213504000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "resnet.eval()\n",
    "total_macs = 0\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(resnet_testloader, 0)):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            \n",
    "            inputs, labels = inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            inputs = inputs.unsqueeze(1)\n",
    "            inputs = inputs.repeat(1, 3, 1, 1)\n",
    "            inputs = inputs.to(device)\n",
    "            # forward + backward + optimize\n",
    "            # TODO\n",
    "            outputs = ...\n",
    "            total_macs += get_model_macs(resnet, (inputs, 0, False))\n",
    "            \n",
    "            \n",
    "            indices = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            total_correct += torch.sum(labels == indices)\n",
    "\n",
    "\n",
    "print(f'Accuracy: {total_correct/6000} %')\n",
    "print('Total MACS: ', total_macs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the accuracy with a regular ResNet-18?\n",
    "\n",
    "Inference Speed?\n",
    "\n",
    "Total MACS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_early = EarlyExitResNet18()\n",
    "resnet_early = resnet.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "resnet_optimizer = optim.Adam(resnet.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in the code below to train the early exit network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 50] loss: 2.892\n",
      "[1, 100] loss: 1.327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:08<01:14,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 50] loss: 0.741\n",
      "[2, 100] loss: 0.696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:16<01:07,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 50] loss: 0.506\n",
      "[3, 100] loss: 0.471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:25<00:59,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 50] loss: 0.357\n",
      "[4, 100] loss: 0.366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:33<00:51,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 50] loss: 0.269\n",
      "[5, 100] loss: 0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:42<00:42,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 50] loss: 0.209\n",
      "[6, 100] loss: 0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:51<00:34,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 50] loss: 0.155\n",
      "[7, 100] loss: 0.165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:59<00:25,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 50] loss: 0.127\n",
      "[8, 100] loss: 0.143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:08<00:17,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 50] loss: 0.092\n",
      "[9, 100] loss: 0.087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:16<00:08,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 50] loss: 0.056\n",
      "[10, 100] loss: 0.062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:25<00:00,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "resnet_losses = []\n",
    "for epoch in tqdm(range(10)):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(resnet_trainloader, 0):\n",
    "        step += 1\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        inputs = inputs.repeat(1, 3, 1, 1)\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        resnet_optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "        # forward + backward + optimize\n",
    "        # TODO Use w_0 = 1 and w_i = 0.3 for i > 0\n",
    "        outputs = ...\n",
    "        loss = ...\n",
    "        loss.backward()\n",
    "        resnet_optimizer.step()\n",
    "        resnet_losses.append(loss.item())\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 50:.3f}')\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in the code below to evaluate the early exit network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [00:01, 23.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9078333377838135 %\n",
      "Num Exiting:  {0: 17, 1: 16, 2: 8, 3: 6}\n",
      "Total MACS:  2305700339712\n",
      "47\n",
      "Entropies:  0.004162853 0.019386116 0.06340146 0.08171481 0.098951355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "resnet_early.eval()\n",
    "exiting_points = {0:0, 1:0, 2:0, 3:0}\n",
    "entropies = []\n",
    "total_early_macs = 0\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    total_early_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(resnet_testloader, 0)):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            \n",
    "            inputs, labels = inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            inputs = inputs.unsqueeze(1)\n",
    "            inputs = inputs.repeat(1, 3, 1, 1)\n",
    "            inputs = inputs.to(device)\n",
    "            # forward + backward + optimize\n",
    "            # TODO Use an entropy tolerance of 0.05\n",
    "            outputs, num, curr_entropy = ...\n",
    "            entropies.append(curr_entropy)\n",
    "            total_early_macs += get_model_macs(resnet_early, (inputs, 0.05))\n",
    "            \n",
    "            \n",
    "            exiting_points[num] += 1\n",
    "            \n",
    "            \n",
    "            indices = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            total_early_correct += torch.sum(labels == indices)\n",
    "\n",
    "\n",
    "print(f'Accuracy: {total_correct/6000} %')\n",
    "print('Num Exiting: ', exiting_points)\n",
    "print('Total MACS: ', total_early_macs)\n",
    "entropies = sorted(entropies)\n",
    "print(len(entropies))\n",
    "print('Entropies: ', entropies[0], entropies[len(entropies)//4], entropies[len(entropies)//2], entropies[3*len(entropies)//4], entropies[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the accuracy with an early exit ResNet-18?\n",
    "\n",
    "Inference Speed?\n",
    "\n",
    "Total MACS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.446941498224665"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Ratio of Standard to Early Exit MACS: {total_macs/total_early_macs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy\n",
    "\n",
    "Play around with the entropy tolerance to see how low you can get the MACS while keeping 90 percent or greater accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did early exit do? Compare accuracy and MACS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Question\n",
    "\n",
    "No solutions will be provided for this question:\n",
    "\n",
    "When would we use early exit, versus just using a smaller model? What factors should we consider? \n",
    "\n",
    "How does early exit relate to example difficulty?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
